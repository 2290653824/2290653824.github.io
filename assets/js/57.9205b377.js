(window.webpackJsonp=window.webpackJsonp||[]).push([[57],{379:function(r,t,v){"use strict";v.r(t);var a=v(4),_=Object(a.a)({},(function(){var r=this,t=r._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":r.$parent.slotKey}},[t("h2",{attrs:{id:""}},[t("a",{staticClass:"header-anchor",attrs:{href:"#"}},[r._v("#")])]),r._v(" "),t("h2",{attrs:{id:"什么是内存屏障"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#什么是内存屏障"}},[r._v("#")]),r._v(" 什么是内存屏障")]),r._v(" "),t("p",[r._v("是一种"),t("strong",[r._v("屏障指令")]),r._v("，它使得CPU或编译器对"),t("strong",[r._v("屏障指令的前 或 后")]),r._v(" 所发出的内存操作 "),t("strong",[r._v("执行一个排序的约束")]),r._v("。也叫做内存栅栏 或栅栏指令")]),r._v(" "),t("h2",{attrs:{id:"内存屏障的能力"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#内存屏障的能力"}},[r._v("#")]),r._v(" 内存屏障的能力")]),r._v(" "),t("ol",[t("li",[r._v("阻止屏障两边的指令的重排序")])]),r._v(" "),t("p",[r._v("屏障后的指令不能排序到屏障前，屏障前的指令不能排序到屏障后。")]),r._v(" "),t("ol",{attrs:{start:"2"}},[t("li",[r._v("写数据的时候， 如果加了写屏障的话，强制把写缓冲的数据刷回到主内存中（可见性）")]),r._v(" "),t("li",[r._v("读数据的时候，加了读屏障的话，会让工作内存/CPU高速缓存的数据失效，会重新到主内存中获取新数据。")])]),r._v(" "),t("p",[r._v("综上可见：与可见性和指令重排序都有关")]),r._v(" "),t("p",[r._v("内存屏障分类")]),r._v(" "),t("ol",[t("li",[r._v("读屏障：Load Barrier。在读指令之前插入读屏障。 会让工作内存/CPU高速缓存的数据失效，会重新到主内存中获取新数据。")]),r._v(" "),t("li",[r._v("写屏障：store Barrier。在写指令之后插入写屏障，强制把写缓冲的数据刷回到主内存中")])]),r._v(" "),t("h2",{attrs:{id:"重排序和内存屏障的关系"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#重排序和内存屏障的关系"}},[r._v("#")]),r._v(" 重排序和内存屏障的关系")]),r._v(" "),t("ol",[t("li",[r._v("重排序可能会给程序带来问题，因此，有些时候，我们希望告诉JVM，这里不需要排序")]),r._v(" "),t("li",[r._v("对于编译器的重排序，JMM会根据重排序的规则，禁止特定类型的编译器重排序")]),r._v(" "),t("li",[r._v("对于处理器的重排序，java编译器在生成指令序列的适当位置，插入内存屏障指令，来禁止特定类型的处理器排序。")])]),r._v(" "),t("h2",{attrs:{id:"jmm中的内存屏障"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#jmm中的内存屏障"}},[r._v("#")]),r._v(" JMM中的内存屏障")]),r._v(" "),t("p",[r._v("读读屏障 "),t("strong",[r._v("LoadLoad Barriers")]),r._v("： Load1； LoadLoad ；Load2")]),r._v(" "),t("blockquote",[t("ul",[t("li",[t("p",[r._v("禁止重排序：访问Load2的读操作一定不会重排到Load1之前")])]),r._v(" "),t("li",[t("p",[r._v("保证Load2在读取的时候，自己缓存内到相应的数据失效，Load2会去主内存获取最新的数据")])])]),r._v(" "),t("p",[r._v("设想一下为什么load1时不会有上面的清楚工作内存的数据呢？原因：假设我们都为变量a加上了内存屏障，那么第一次读变量a时，是不需要清楚缓存的，因为之前没有读过。")])]),r._v(" "),t("p",[r._v("读写屏障 "),t("strong",[r._v("LoadStore Barriers")]),r._v("：Load1；LoadStore；Store2")]),r._v(" "),t("blockquote",[t("p",[r._v("禁止重排序：一定是Load1读取到数据完成后，才能让Store2及其之后的写出操作的数据，被其它线程看到")])]),r._v(" "),t("p",[r._v("写写屏障 "),t("strong",[r._v("StoreStore Barriers")]),r._v("：Store1；StoreStore；Store2")]),r._v(" "),t("blockquote",[t("ul",[t("li",[r._v("禁止重排序：一定是Store1的数据写出到主内存完成后，才能让store2及其之后的写出操作的数据，被其它县城看到")]),r._v(" "),t("li",[r._v("还可以保证Store1指令写出去的数据，会强制被刷新到主内存中")])])]),r._v(" "),t("p",[r._v("写读屏障"),t("strong",[r._v("StoreLoad Barriers")]),r._v(" ：Store1；StoreLoad；Load2")]),r._v(" "),t("blockquote",[t("ul",[t("li",[t("p",[r._v("禁止重排序：一定是store1的数据写出到主内存完成后，才能让Load2来读取数据")])]),r._v(" "),t("li",[t("p",[r._v("同时保证：强制把写写缓冲区的数据刷回到主内存中；让工作内存高速缓存当中缓存数据失效，重新到主内存中获取新的数据")])])])]),r._v(" "),t("h2",{attrs:{id:"为什么storeloadbarriers是最重的"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#为什么storeloadbarriers是最重的"}},[r._v("#")]),r._v(" 为什么StoreLoadBarriers是最重的？")]),r._v(" "),t("p",[r._v("重：就是跟内存交互次数多，交互延迟较大、消耗资源多")]),r._v(" "),t("p",[r._v("LoadLoad只有读屏障功能")]),r._v(" "),t("p",[r._v("StoreStore只有写屏障功能")]),r._v(" "),t("p",[t("strong",[r._v("而StoreLoad同时拥有所有的功能")])]),r._v(" "),t("h2",{attrs:{id:"扩展"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#扩展"}},[r._v("#")]),r._v(" 扩展")]),r._v(" "),t("p",[r._v("​\t这些屏障指令并不是处理器真实的执行指令，他们只是JMM定义出来的、跨平台的指令。")]),r._v(" "),t("p",[r._v("​\t因为不同硬件实现内存屏障的方式并不相同，JMM为了屏蔽这些底层硬件平台的不同，抽象出了这些内存指令屏障，在运行的时候，由JVM来为不同的平台生成效应的机器码。")]),r._v(" "),t("p",[r._v("这些内存屏障指令，在不同的硬件平台上，可能会在一些优化，从而只支持部分的JMM的内存屏障指令")]),r._v(" "),t("p",[r._v("例如在x86机器上，就只有StoreLoad操作，其他都不支持，仅仅是个空操作")]),r._v(" "),t("p",[t("strong",[r._v("volatile使用的就是StoreLoad屏障")])])])}),[],!1,null,null,null);t.default=_.exports}}]);